{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "from face_recognition import FaceFeaturesExtractor,preprocessing, FaceRecogniser\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from PIL import ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings\t  face_recognition.ipynb  images   README.md  Train_model\r\n",
      "face_recognition  fonts\t\t\t  LICENSE  results\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f5a095665b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files in images and generating embeddings.\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/'\n",
    "path_embeddings = 'embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extractor = FaceFeaturesExtractor()\n",
    "dataset = datasets.ImageFolder(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_embeddings(image_path,path_embeddings):\n",
    "    transform = transforms.Compose([\n",
    "        preprocessing.ExifOrientationNormalize(),\n",
    "        transforms.Resize(1024)\n",
    "    ])\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for img_path, label in dataset.samples:\n",
    "        print(img_path)\n",
    "        _, embedding = features_extractor(transform(Image.open(img_path).convert('RGB')))\n",
    "        if embedding is None:\n",
    "            print(\"Could not find face on {}\".format(img_path))\n",
    "            continue\n",
    "        if embedding.shape[0] > 1:\n",
    "            print(\"Multiple faces detected for {}, taking one with highest probability\".format(img_path))\n",
    "            embedding = embedding[0, :]\n",
    "        embeddings.append(embedding.flatten())\n",
    "        labels.append(label)\n",
    "    Embeddings = np.stack(embeddings)\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    np.savetxt(path_embeddings+'embeddings.txt', embeddings)\n",
    "    np.savetxt(path_embeddings+ 'labels.txt', np.array(labels, dtype=np.str).reshape(-1, 1), fmt=\"%s\")\n",
    "    joblib.dump(idx_to_class, path_embeddings + 'idx_to_class.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/Jeans/WIN_20211005_17_45_23_Pro (2).jpg\n",
      "images/Jeans/WIN_20211005_17_45_26_Pro.jpg\n",
      "images/Jeans/WIN_20211005_17_45_28_Pro.jpg\n",
      "images/Jeans/WIN_20211005_17_45_30_Pro.jpg\n",
      "images/Jeans/WIN_20211005_17_45_36_Pro.jpg\n",
      "images/Jeans/WIN_20211005_17_45_37_Pro.jpg\n",
      "images/Jeans/WIN_20211005_17_45_39_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_05_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_11_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_13_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_16_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_22_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_24_Pro.jpg\n",
      "images/Juan_diego/WIN_20211005_17_38_25_Pro.jpg\n",
      "images/daniel/WIN_20211005_06_53_27_Pro.jpg\n",
      "images/daniel/WIN_20211005_06_53_29_Pro.jpg\n",
      "images/daniel/WIN_20211005_06_53_31_Pro.jpg\n",
      "images/daniel/daniel_1.jpg\n",
      "images/daniel/daniel_2.jpg\n",
      "images/daniel/daniel_3.jpg\n",
      "images/daniel/daniel_4.jpg\n",
      "images/daniel/daniel_5.jpg\n",
      "images/daniel/daniel_6.jpg\n",
      "images/daniel/daniel_7.jpg\n",
      "images/daniel_cepeda/WIN_20211005_18_09_32_Pro.jpg\n",
      "images/daniel_cepeda/WIN_20211005_18_09_37_Pro.jpg\n",
      "images/daniel_cepeda/WIN_20211005_18_09_39_Pro.jpg\n",
      "images/daniel_cepeda/WIN_20211005_18_09_46_Pro.jpg\n",
      "images/daniel_cepeda/WIN_20211005_18_09_49_Pro.jpg\n",
      "images/jose_daniel/WIN_20211005_18_10_31_Pro.jpg\n",
      "Multiple faces detected for images/jose_daniel/WIN_20211005_18_10_31_Pro.jpg, taking one with highest probability\n",
      "images/jose_daniel/WIN_20211005_18_10_32_Pro.jpg\n",
      "images/jose_daniel/WIN_20211005_18_10_33_Pro.jpg\n",
      "images/jose_daniel/WIN_20211005_18_10_37_Pro.jpg\n",
      "images/jose_daniel/WIN_20211005_18_10_38_Pro.jpg\n",
      "images/jose_daniel/WIN_20211005_18_10_39_Pro.jpg\n",
      "images/sara_2/WIN_20211005_18_10_05_Pro.jpg\n",
      "images/sara_2/WIN_20211005_18_10_10_Pro.jpg\n",
      "images/sara_2/WIN_20211005_18_10_12_Pro.jpg\n",
      "images/sara_2/WIN_20211005_18_10_19_Pro.jpg\n",
      "images/sara_2/WIN_20211005_18_10_22_Pro.jpg\n"
     ]
    }
   ],
   "source": [
    "generate_new_embeddings(image_path,path_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved data\n",
    "embeddings_path = 'embeddings/embeddings.txt'\n",
    "labels_path = 'embeddings/labels.txt'\n",
    "idx_to_class_path = 'embeddings/idx_to_class.pkl'\n",
    "embeddings = np.loadtxt(embeddings_path)\n",
    "labels = np.loadtxt(labels_path, dtype='int').tolist()\n",
    "idx_to_class = joblib.load(idx_to_class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model\n",
    "model= LogisticRegression(solver='lbfgs', multi_class='multinomial', C=10, max_iter=10000)\n",
    "clf = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(embeddings, labels)\n",
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Train_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path= 'Train_model.pkl'\n",
    "joblib.dump(FaceRecogniser(features_extractor, best_model, idx_to_class), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25091575 0.25091575 0.27655678 0.9029304  0.97619048 0.97619048\n",
      " 0.97619048]\n",
      "[0.04070716 0.04070716 0.07670473 0.08863409 0.03367175 0.03367175\n",
      " 0.03367175]\n"
     ]
    }
   ],
   "source": [
    "print(clf.cv_results_['mean_test_score'])\n",
    "print(clf.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bb_on_img(faces, img):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    fs = max(20, round(img.size[0] * img.size[1] * 0.000005))\n",
    "    font = ImageFont.truetype('fonts/font.ttf', fs)\n",
    "    margin = 5\n",
    "\n",
    "    for face in faces:\n",
    "        print(face.top_prediction.confidence)\n",
    "        if face.top_prediction.confidence > 0.7:\n",
    "            text = \"%s %.2f%%\" % (face.top_prediction.label.upper(), face.top_prediction.confidence * 100)\n",
    "        else:\n",
    "            text='Desconocido'\n",
    "        text_size = font.getsize(text)\n",
    "\n",
    "        # bounding box\n",
    "        draw.rectangle(\n",
    "            (\n",
    "                (int(face.bb.left), int(face.bb.top)),\n",
    "                (int(face.bb.right), int(face.bb.bottom))\n",
    "            ),\n",
    "            outline='green',\n",
    "            width=2\n",
    "        )\n",
    "\n",
    "        # text background\n",
    "        draw.rectangle(\n",
    "            (\n",
    "                (int(face.bb.left - margin), int(face.bb.bottom) + margin),\n",
    "                (int(face.bb.left + text_size[0] + margin), int(face.bb.bottom) + text_size[1] + 3 * margin)\n",
    "            ),\n",
    "            fill='black'\n",
    "        )\n",
    "\n",
    "        # text\n",
    "        draw.text(\n",
    "            (int(face.bb.left), int(face.bb.bottom) + 2 * margin),\n",
    "            text,\n",
    "            font=font\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces found:  1\n",
      "0.480703141424811\n"
     ]
    }
   ],
   "source": [
    "img_path = 'images/sara_2/WIN_20211005_18_10_05_Pro.jpg'\n",
    "img_path = 'images/Jeans/WIN_20211005_17_45_30_Pro.jpg'\n",
    "img_path = '/home/daniel/Downloads/barack.jpeg' \n",
    "#img_path = '/home/daniel/Downloads/flaca.jpeg'\n",
    "save_dir = 'results/'\n",
    "preprocess = preprocessing.ExifOrientationNormalize()\n",
    "img = Image.open(img_path)\n",
    "filename = img.filename\n",
    "img = preprocess(img)\n",
    "img = img.convert('RGB')\n",
    "faces = joblib.load(model_path)(img)\n",
    "if not faces:\n",
    "    print('No faces were found')\n",
    "else:\n",
    "    print('Faces found: ',str(len(faces)))\n",
    "    draw_bb_on_img(faces, img)\n",
    "    if save_dir is not None:\n",
    "        basename = os.path.basename(filename)\n",
    "        name = basename.split('.')[0]\n",
    "        ext = basename.split('.')[1]\n",
    "        img.save('{}_tagged.{}'.format(save_dir+name, ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
